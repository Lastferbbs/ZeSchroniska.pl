from bs4 import BeautifulSoup
import requests
import json
import re
from datetime import datetime


import os
from django.conf import settings

# file_path = os.path.join(settings.BASE_DIR, "relative_path")

# file_path = os.path.join(
#     settings.BASE_DIR, "Zeschroniska.pl/zeschroniska/shelters/scrapers/"
# )
import sys

sys.path.append("/home/bsc-node/sol_exp/Zeschroniska.pl/zeschroniska")
from shelters.scrapers.base_classes import Dog, Schronisko
from shelters.scrapers.headers import headers

# TODO - brak podstrony dla zwierzaka, jakoś to spróbować obejść
class SchroniskoDG(Schronisko):
    def __init__(
        self,
        name="schronisko_amicus_glogow",
        address="ul. Norwida 1, 67-200 Głogów",
        phone="667-966-567",
        email="amicus.glogow@wp.pl",
        website="http://amicus.glogow.pl/",
        link_dogs="http://amicus.glogow.pl/rehoming/dog-rehoming/page/",
        link_cats="http://amicus.glogow.pl/rehoming/cat-rehoming/page/",
    ):
        Schronisko.__init__(
            self, name, address, phone, email, website, link_dogs, link_cats
        )

    def get_dogs_content(self, page):
        website = requests.get(self.link_dogs + page, headers=headers)
        return website.content

    def get_cats_content(self, page):
        website = requests.get(self.link_cats + page, headers=headers)
        return website.content

    def get_availables_pages_for_animal(self, type_animal):
        if type_animal == "dogs":
            soup = BeautifulSoup(self.get_dogs_content("1"), "lxml")

        if type_animal == "cats":
            soup = BeautifulSoup(self.get_cats_content("1"), "lxml")

        available_pages = soup.find_all("a", "page")
        max_page_number = available_pages[-1].text
        return max_page_number

    def get_all_dogs_from_website(self):
        dogs_list = set()

        for page in range(
            1, int(self.get_availables_pages_for_animal("dogs")) + 1
        ):  # iterate over all pages
            soup = BeautifulSoup(self.get_dogs_content(str(page)), "lxml")
            dogs_listings = soup.find_all("a", "cmsmasters_img_link preloader")
            for dog in dogs_listings:
                dogs_list.add(dog.attrs["href"])
        return dogs_list

    def get_all_cats_from_website(self):
        cats_list = set()

        for page in range(1, int(self.get_availables_pages_for_animal("cats")) + 1):
            soup = BeautifulSoup(self.get_cats_content(str(page)), "lxml")
            cats_listings = soup.find_all("a", "cmsmasters_img_link preloader")
            for cat in cats_listings:
                cats_list.add(cat.attrs["href"])
        return cats_list


class DogDG(Dog):
    def __init__(
        self,
        link,
        animal_type,
        current_place,
    ):
        Dog.__init__(self, link, animal_type, current_place)

    def download_dog_link_content(self):
        self.link_content = requests.get(self.link, headers=headers).content
        test = 1

    def set_dog_details(self):
        description_details_parameters_setter = {
            "Data:": self.set_publication_date,
            "Orientacyjny wiek": self.set_age,  # TODO: normalize date format
            "Płeć": self.set_sex,
            "Rasa": self.set_breed,
            "Wielkość": self.set_size,
            "Kastracja/Sterylizacja": self.set_sterilized,
        }
        soup = BeautifulSoup(self.link_content, "lxml")
        name = soup.find("h3", "cmsmasters_project_title entry-title").text
        self.set_name(name)
        description = soup.find(
            "div", "cmsmasters_project_content entry-content", "p"
        ).text.replace("\n", "")
        self.set_description(description)
        parameters = soup.find_all(
            "div", "project_details_item"
        )  # get all dog's details
        for parameter in parameters:
            if parameter.contents[0].text in description_details_parameters_setter:
                if (
                    parameter.contents[0].text == "Data:"
                ):  # taking last updated date which is on slot 1
                    description_details_parameters_setter[parameter.contents[0].text](
                        parameter.contents[1].contents[1].text
                    )
                else:  # taking other details which are on slot 0
                    description_details_parameters_setter[parameter.contents[0].text](
                        parameter.contents[1].contents[0].text
                    )

    def set_dog_pictures(self):
        soup = BeautifulSoup(self.link_content, "lxml")
        pictures = soup.find_all("img", "full-width")
        for picture in pictures:
            self.add_picture(picture.attrs["src"])


shelter = SchroniskoDG()
print(shelter.get_availables_pages_for_animal("dogs"))
print(shelter.get_availables_pages_for_animal("cats"))
